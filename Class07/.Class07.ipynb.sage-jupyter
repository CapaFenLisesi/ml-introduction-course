{"kernelspec":{"display_name":"Python 2 (SageMath)","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}}
{"cell_type":"markdown","metadata":{"collapsed":false},"source":"# Class 07\n## ML Models: Decision Trees\n\nWe will cover a new type of machine learning algorithm in this class: decision trees. We will also talk about ensemble methods and how we can use them to improve the performance of our machine learner.\n\n### Classification Decision Trees\n\nWe'll start by using a decision tree classifier. We'll use the same set of data as we used in Class 06. Again, that will allow us to compare the algorithm head-to-head with the other classifiers we've used previously. A **decision tree** works by splitting the data into pieces while trying to maximize the uniformity of each piece. Although we won't dive deeply into how the algorithm works, [you can read a great tutorial here](https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/).\n\nFor example we start with a group of 10 people, half who identify as male and half as female. The most uniform split will be to divide the group into two sub-groups known as nodes. We can cleanly split the group so that each sub-group is uniformly populated. The tree builds a set of decision nodes to split the group so as to end up with the best set of rules to predict the output labels.\n\nThe tree will continue to split until it reaches a point where it can't split the data anymore. These end points are called **leaf nodes**. The number of data points allowed to be in a leaf node is one of the hyperparameters we have to tune. Going back to our example, if we set the minimum size of the leaf node to 5 people, the decision tree will end after doing a single split. However, if we let the leaf nodes be smaller, it may split up the sub-groups by age, height, or by other features.\n\nThis will make more sense as we try it out, so let's get started."}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<matplotlib.text.Text at 0x7f58e92fb410>"},"execution_count":1,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::4a873554-cac3-4649-a87e-9b88e8557eb0","text/plain":"<matplotlib.figure.Figure at 0x7f58eafb9990>"},"metadata":{},"output_type":"display_data"}],"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\n\n#Note the new use of the dtype option here. We can directly tell pandas to use the Speed column as a category in one step.\nspeeddf = pd.read_csv(\"../Class04/Class04_speed_data.csv\",dtype={'Speed':'category'})\n\n#We'll use a different tool to plot the data now that we know how to group the data by a category. This will help us make better combined plots later on.\ngroups = speeddf.groupby('Speed')\n\n# Plot\ntrainfig, ax = plt.subplots()\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\n    ax.set_aspect(1)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')"}
{"cell_type":"markdown","metadata":{},"source":"We'll import the `DecisionTreeClassifier` and use all of the default values except for the `random_state`. We'll provide that so that the output is consistent run-to-run. The decision tree classifier uses the random number generator to make decisions about branching, so if we don't set this, we'll get different results every time we run the algorithm."}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/projects/sage/sage/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"},{"name":"stdout","output_type":"stream","text":"Class-dependent Metrics\nSensitivity/Recall Score: [ 0.89473684  0.94354839]\nPrecision Score: [ 0.90666667  0.936     ]\nF1 Score: [ 0.90066225  0.93975904]\n\nClass-independent Metrics\nAccuracy Score: 0.925\nMatthews Correlation Coefficient (MCC): 0.840473092852\n"},{"data":{"image/png":"smc-blob::1066c35d-7384-4464-93bb-105622361b53","text/plain":"<matplotlib.figure.Figure at 0x7f591f5aed50>"},"metadata":{},"output_type":"display_data"}],"source":"import numpy as np\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create our decision boundary mesh\n# point in the mesh\nx_min = 0.0; x_max = 1.0 # Mesh x size\ny_min = 0.0; y_max = 1.0  # Mesh y size\nh = .01  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max+h, h), np.arange(y_min, y_max+h, h))\n\n# Split the data into training and testing sets and prepare the features and labels\ntrain, test = train_test_split(speeddf, test_size=0.2, random_state=23)\nfeatures_train = train[['Grade','Bumpiness']].values\nlabels_train = train['Speed'].values\nfeatures_test = test[['Grade','Bumpiness']].values\nlabels_test = test['Speed'].values\nclass_labels = [\"slow\", \"fast\"]\n\n# Load the model and fit the data\ndtmodel = DecisionTreeClassifier(random_state=32)\ndtmodel.fit(features_train,labels_train)\n\ny_pred = dtmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(dtmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\n\nimport sklearn.metrics as metrics\n\nrecall_score = metrics.recall_score(labels_test, y_pred,labels=class_labels,average=None)\nprec_score = metrics.precision_score(labels_test, y_pred,labels=class_labels,average=None)\nf1_score = metrics.f1_score(labels_test, y_pred,labels=class_labels,average=None)\n\nacc_score = metrics.accuracy_score(labels_test, y_pred)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\n\nprint(\"Class-dependent Metrics\")\nprint(\"Sensitivity/Recall Score: {}\".format(recall_score))\n\nprint(\"Precision Score: {}\".format(prec_score))\nprint(\"F1 Score: {}\".format(f1_score))\n\nprint(\"\\nClass-independent Metrics\")\nprint(\"Accuracy Score: {}\".format(acc_score))\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"Take a look at the decision boundary for this classifier: it is all over the place! The tree tries to account for every point and so it creates braches where there shouldn't be branches. We have a classic case of overfitting! And the model performance isn't great either with an MCC of 0.84. It is time to tune the hyperparameters to see if we can do better. Let's start by tuning the minimum number of samples in the leaf nodes of the tree."}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.851443123939\n"},{"data":{"image/png":"smc-blob::25e04697-25d1-49ae-8422-44bef2efdf7c","text/plain":"<matplotlib.figure.Figure at 0x7f58e9508fd0>"},"metadata":{},"output_type":"display_data"}],"source":"# Load the model and fit the data\ndtmodel = DecisionTreeClassifier(min_samples_leaf=10,random_state=32)\ndtmodel.fit(features_train,labels_train)\n\ny_pred = dtmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(dtmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"So our decision boundary is cleaned up significantly *and* we got a bump in the test performance of the model. Let's check one more value to see if we can do any better."}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.894625126632\n"},{"data":{"image/png":"smc-blob::786d3ecd-8d17-47a3-9a1a-e42402033f5e","text/plain":"<matplotlib.figure.Figure at 0x7f58e40ddc50>"},"metadata":{},"output_type":"display_data"}],"source":"# Load the model and fit the data\ndtmodel = DecisionTreeClassifier(min_samples_leaf=5,random_state=32)\ndtmodel.fit(features_train,labels_train)\n\ny_pred = dtmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(dtmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"We got an MCC of 0.894 with a fairly simple decision boundary. That's good! There are, perhaps, a few too many wiggles in the boundary, but overall it is looking pretty good. Note that all of the boundaries are straight lines- that is because the decision tree is choosing cutoff values of \"Grade\" and \"Bumpiness\" to split the dataset along those lines. Overall this isn't too bad."}
{"cell_type":"markdown","metadata":{},"source":"### Ensemble Methods\n\nThe decision tree did a reasonable job of modeling our data but we only used *one* tree and *one* set of random values. What if we could do this many times and average the results. There are tools to do that! One of the strategies that ensemble methods will use is to scramble which of the training features it uses for each trial run. Let's take a quick look at that method, called a \"bootstrap\" sample.\n\nWe will start with 100 data points in our training sample. The ensemble model will break this up into 10 chunks of 10 data points each (each chunk labeled A-J). For the first model it takes chunks A-I and trains on them, then validates that model with chunk J. The next model will take chunks A-H and J, leaving chunk I for validation. It repeats this as many times as it needs. Thus the ensemble is doing training and validation all on the same set of data!\n\n#### Data Snooping Warning\n\n> Although the ensemble is doing its own validation, that doesn't mean you can train with all of your data. You still need to keep the test data locked away and not used for training. This means we can compare the ensemble model to the other models without cheating ourselves.\n\nWe'll try out the simplest version of this first, called the `RandomForestClassifier`."}
{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.883622738921\n"},{"data":{"image/png":"smc-blob::0bbe477d-1c72-4214-8401-082214d61a70","text/plain":"<matplotlib.figure.Figure at 0x7f58deea4910>"},"metadata":{},"output_type":"display_data"}],"source":"# Load the model and fit the data\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfmodel = RandomForestClassifier(n_estimators=100,random_state=32)\nrfmodel.fit(features_train,labels_train)\n\ny_pred = rfmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(rfmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"We see that the ensemble does a reasonable job- perhaps not better, in this case, than the decision tree by itself. However, there is something else that we get out of using the ensemble: it will tell us the relative importance of the different features it used in making the decision boundary. The list of feature importances are given in terms of percentage importance of each feature. This can be helpful in deciding which features to use as inputs to the model. If the ensemble says that a feature is not very important, you may be able to drop it and simplify your model.\n\nLet's look at our feature importances:"}
{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"array([ 0.48856166,  0.51143834])"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"rfmodel.feature_importances_"}
{"cell_type":"markdown","metadata":{},"source":"Both features (Grade and Bumpiness) have just about the same importance in our model (about 50% each). That isn't too surprising since we faked the data to begin with...\n\nLet's try some other ensemble methods to see how they work.\n\n### AdaBoost Classifier\n\nThis is another ensemble classifier that iteratively learns using a series of weights."}
{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.88302869249\n"},{"data":{"image/png":"smc-blob::a7c946fa-dc9e-4bd2-b143-8878cc51b60c","text/plain":"<matplotlib.figure.Figure at 0x7f58deef7590>"},"metadata":{},"output_type":"display_data"}],"source":"# Load the model and fit the data\nfrom sklearn.ensemble import AdaBoostClassifier\n\nabcmodel = AdaBoostClassifier(n_estimators=100,random_state=32)\nabcmodel.fit(features_train,labels_train)\n\ny_pred = abcmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(abcmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"### XGBoost\n\nThis last ensemble method is new enough to not be a part of the regular sklearn toolbox yet. However, it has made a fairly big splash in the machine learning community for its performance on real-world data."}
{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.904792426006\n"},{"data":{"image/png":"smc-blob::0128fb59-99c3-49df-96f0-e4eb8ad7d342","text/plain":"<matplotlib.figure.Figure at 0x7f58def26f90>"},"metadata":{},"output_type":"display_data"}],"source":"import xgboost\nxgbmodel = xgboost.XGBClassifier(n_estimators=100, seed=32)\nxgbmodel.fit(features_train,labels_train)\n\ny_pred = xgbmodel.predict(features_test)\n\n# Predict the boundary\nZ = pd.Series(xgbmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1.2,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))"}
{"cell_type":"markdown","metadata":{},"source":"So we get a little better performance on this dataset with the XGBoost algorithm. As quick side note here: XGBoost only works out-of-the-box on SageMath using their Python 2 kernel. If you want to use the Python 3 kernel like we have for the other classes, you'll need to install XGBoost for the other kernel.\n\n## In-class Activity\n\nWe can also use decision trees to model continuous data for regressions. I want you to look up the documentation for how to do that and implement the regressions on the same data we used in Class 06. \n\n## Assignment\n\nYour assignment this week is to try using the decision tree models on your own data. Record how long it took to train the models and how well they performed compared to our previous classifier/regression models."}