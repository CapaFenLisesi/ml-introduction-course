{"kernelspec":{"display_name":"Python 3 (Anaconda)","language":"python","name":"anaconda3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"}}
{"cell_type":"markdown","metadata":{"collapsed":false},"source":"# Class 03 - Supplemental\n## Using Categorical data in machine learning\n\nNow that we've created some categorical data or other created features, we would like to use them as inputs for our machine learning algorithm. However, we need to tell the computer that the categorical data isn't the same as other numerical data. For example, I could have the following two types of categorical data:\n\n1. Ordered Categorical Data: items like rankings or scales where the size of the output corresponds to some placement along a line. One example is the grade scale where A=4, B=3, C=2, D=1, F=0.\n2. Unordered Categorical Data: Categories like gender, race, state, or color don't have any rational scale to place them on. So assigning red=4, blue=3 doesn't mean red is 'better' than blue.\n\nWe want to treat both of these slightly differently. We've got a sample dataset with both types of categorical data in it to work with. Our goal will be to predict the Output value."}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Date       object\nRank       object\nState      object\nOutput    float64\ndtype: object\n"},{"data":{"text/html":"smc-blob::c343edb6-263a-48ea-b20d-07df450a4249","text/plain":"                   Date Rank State      Output\n0  2004-03-15T12:45:32Z    E    NH  211.813359\n1  2004-03-15T20:50:02Z    F    MO  210.218858\n2  2004-03-16T05:46:43Z    E    MT  210.915793\n3  2004-03-16T22:19:24Z    D    LA  209.355303\n4  2004-03-17T05:01:51Z    D    MD  205.653412"},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":"import pandas as pd\nimport numpy as np\n\nsampledata = pd.read_csv('Class03_supplemental_data.csv')\n\nprint(sampledata.dtypes)\nsampledata.head()"}
{"cell_type":"markdown","metadata":{"collapsed":false},"source":"We can turn the date column into a real datetime object and get days since the first day in order to work with a more reasonable set of values."}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"Date                      object\nRank                      object\nState                     object\nOutput                   float64\nDate2             datetime64[ns]\nDaysSinceStart           float64\ndtype: object"},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":"sampledata[\"Date2\"] = pd.to_datetime(sampledata[\"Date\"])\nfirstdate = sampledata['Date2'][0]\nsampledata['DaysSinceStart'] = sampledata['Date2'].apply(lambda date: ((date - firstdate ).seconds)/86400.0) # divided by the number of seconds in a day\nsampledata.dtypes"}
{"cell_type":"markdown","metadata":{},"source":"## Ordered Categorical Values\n\nThe 'Rank' column are ranked categorical values where the ranking matters on a linear scale. So we can create a categorical column for these values right away. We are lucky here that the values are in alphabetical order - pandas can pick out that order and use it for us."}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')\n"},{"data":{"text/plain":"1    5\n2    4\n3    3\n4    3\n5    4\n6    2\n7    1\n8    1\n9    2\ndtype: int8"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"sampledata['CatRank'] = sampledata['Rank'].astype('category')\nprint(sampledata[\"CatRank\"].cat.categories)\nsampledata[\"CatRank\"][1:10].cat.codes"}
{"cell_type":"markdown","metadata":{},"source":"## Unordered Categorical Values\n\nLet's now put the states into a categorical column. Even though Pandas will sort them, there is no real 'rank' for the states"}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Index(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'IA',\n       'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO',\n       'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK',\n       'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI',\n       'WV', 'WY'],\n      dtype='object')\n"},{"data":{"text/plain":"1    23\n2    25\n3    17\n4    19\n5    20\n6    16\n7    23\n8    45\n9    38\ndtype: int8"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"sampledata['CatState'] = sampledata['State'].astype('category')\nprint(sampledata[\"CatState\"].cat.categories)\nsampledata[\"CatState\"][1:10].cat.codes"}
{"cell_type":"markdown","metadata":{},"source":"## Modeling with Categorical Data\n\nLet's split the dataset and try modeling - we want to predict the output value. We need the categorical codes as columns to do this, so we'll take care of that part first."}
{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"Index(['Date', 'Rank', 'State', 'Output', 'Date2', 'DaysSinceStart', 'CatRank',\n       'CatState', 'RankCode', 'StateCode'],\n      dtype='object')"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"sampledata['RankCode'] = sampledata['CatRank'].cat.codes\nsampledata['StateCode'] = sampledata['CatState'].cat.codes\nsampledata.columns"}
{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ntrain1, test1 = train_test_split(sampledata, test_size=0.2, random_state=23)\n\n# Step 1: Create linear regression object\nregr1 = LinearRegression()\n\n# Step 2: Train the model using the training sets\ninputcolumns = ['DaysSinceStart','RankCode','StateCode']\nfeatures = train1[inputcolumns].values\nlabels = train1['Output'].values\n\nregr1.fit(features,labels)"}
{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"RMS Error: 3.576\n"},{"data":{"image/png":"smc-blob::dd4fe046-3fad-496d-b132-db3813e10a7a","text/plain":"<matplotlib.figure.Figure at 0x7ff3c6658240>"},"metadata":{},"output_type":"display_data"}],"source":"# Step 5: Get the predictions\ntestinputs = test1[inputcolumns].values\npredictions = regr1.predict(testinputs)\nactuals = test1['Output'].values\n\n# Step 6: Plot the results\n#\n# Note the change here in how we plot the test inputs. We can only plot one variable, so we choose the first.\n# Also, it no longer makes sense to plot the fit points as lines. They have more than one input, so we only visualize them as points.\n#\nimport matplotlib.pyplot as plt\nplt.scatter(testinputs[:,0], actuals, color='black', label='Actual')\nplt.scatter(testinputs[:,0], predictions, color='blue', label='Prediction')\nplt.legend(loc='upper left', shadow=False, scatterpoints=1)\n\n# Step 7: Get the RMS value\nprint(\"RMS Error: {0:.3f}\".format( np.sqrt(np.mean((predictions - actuals) ** 2))))"}
{"cell_type":"markdown","metadata":{},"source":"So we see that this didn't do a very good job to start with. However, that's not surprising as it used the states as a ranked categorical value when they obviously aren't.\n\n\n## Using Unranked categorical values\n\nWhat we want is called a **dummy variable**. It will tell the machine learning algorithm to look at whether an entry is one of the states or not. Here's basically how it works. Suppose we have two categories: red and blue. Our categorical column may look like this:\n\n| Row | Color |\n|--- |---|\n|0 | red |\n| 1 | red |\n| 2 | blue |\n|3 | red |\n\nWhat we want are two new columns that identify whether the row belongs in one of the categories. We'll use `1` when it belongs and `0` when it doesn't. This is what we get:\n\n| Row | IsRed | IsBlue |\n| --- | --- | ---|\n| 0 | 1 | 0 |\n| 1 | 1 | 0 |\n| 2 | 0 | 1 | \n| 3 | 1 | 0 |\n\n\nWe now use these new dummy variable columns as the inputs: they are binary and will only have a 1 value where the original row matched up with the category column. Here's what it looks like in pandas.\n\n"}
{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::ed249ecd-deb1-440d-a521-226733279c6e","text/plain":"smc-blob::a5ac5730-ed97-4ea7-8904-da97da3295ec"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":"dummydf = pd.get_dummies(sampledata['CatState'],prefix='S')\ndummydf.head()"}
{"cell_type":"markdown","metadata":{},"source":"We now want to join this back with the original set of features so that we can use it instead of the ranked column of data. Here's one way to do that."}
{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::f45ac4e6-58ba-4797-ae7c-74cec9386163","text/plain":"smc-blob::7d4514ce-e20c-42ad-a246-29fb999978d9"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"sampledata2 = sampledata.join(dummydf)\nsampledata2.head()"}
{"cell_type":"markdown","metadata":{},"source":"We now want to select out all 50 columns from the dummy variable. There is a python way to do this easily, since we used the prefix 'S\\_' for each of those columns "}
{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":"inputcolumns = ['DaysSinceStart','RankCode'] + [col for col in sampledata2.columns if 'S_' in col]\n\ntrain2, test2 = train_test_split(sampledata2, test_size=0.2, random_state=23)\n\n# Step 1: Create linear regression object\nregr2= LinearRegression()\n\nfeatures = train2[inputcolumns].values\nlabels = train2['Output'].values\n\nregr2.fit(features,labels)"}
{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"RMS Error: 1.438\n"},{"data":{"image/png":"smc-blob::0dedab18-a7a0-48a6-b99a-1987a73301e8","text/plain":"<matplotlib.figure.Figure at 0x7ff3ce83b358>"},"metadata":{},"output_type":"display_data"}],"source":"# Step 5: Get the predictions\ntestinputs = test2[inputcolumns].values\npredictions = regr2.predict(testinputs)\nactuals = test2['Output'].values\n\nplt.scatter(testinputs[:,0], actuals, color='black', label='Actual')\nplt.scatter(testinputs[:,0], predictions, color='blue', label='Prediction')\nplt.legend(loc='upper left', shadow=False, scatterpoints=1)\n\n# Step 7: Get the RMS value\nprint(\"RMS Error: {0:.3f}\".format( np.sqrt(np.mean((predictions - actuals) ** 2))))"}
{"cell_type":"markdown","metadata":{},"source":"So, you can see we did significantly better by changing the categorical column into a dummy variable. Take a look at your own datasets to see if this is what you should be doing."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":""}