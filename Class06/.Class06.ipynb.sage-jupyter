{"kernelspec":{"display_name":"Python 3 (Anaconda)","language":"python","name":"anaconda3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"}}
{"cell_type":"markdown","metadata":{"collapsed":false},"source":"# Class 06\n## ML Models: Support Vector Machines + Overfitting\n\nWe're going back to machine learning models again! This time we are going to look at another type of machine learning algorithm that will give us the opportunity to adjust *hyperparameters*: inputs to the machine learning model that tell the model how to behave. Tuning the hyperparameters is something of an art- we'll talk about Occam's Razor again and how to balance model performance with model complexity. But we'll start with the Support Vector Machine (SVM) classifier and go from there.\n\n### SVM Classifier\n\nWe'll use the same set of data that we used in Class 04: the classifier data describing the self-driving car road conditions. We'll load in the data and plot it to make sure we know what we are working with."}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<matplotlib.text.Text at 0x7f474af9f240>"},"execution_count":2,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::af88e670-57f9-4a71-bab7-90b724e68d19","text/plain":"<matplotlib.figure.Figure at 0x7f474afc4cc0>"},"metadata":{},"output_type":"display_data"}],"source":"sns.set_style(\"white\")\n\n#Note the new use of the dtype option here. We can directly tell pandas to use the Speed column as a category in one step.\nspeeddf = pd.read_csv(\"../Class04/Class04_speed_data.csv\",dtype={'Speed':'category'})\n\n#We'll use a different tool to plot the data now that we know how to group the data by a category. This will help us make better combined plots later on.\ngroups = speeddf.groupby('Speed')\n\n# Plot\ntrainfig, ax = plt.subplots()\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\n    ax.set_aspect(1)\nax.legend(bbox_to_anchor=(1,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')"}
{"cell_type":"markdown","metadata":{},"source":"The goal, as before, it to build a model to describe the decision boundary between the \"fast\" and \"slow\" categories in our label column. We are going to skip the background information on the SVM for now, but you can [read about how it works on Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine). You can also read about the SVC (support vector classifier)  [on the Scikit Learn pages](http://scikit-learn.org/stable/modules/svm.html).\n\nWe run through the same set of steps that we've used before to get ready to teach the model. We are going to start with the simplest SVM: the linear classifier. This will give us a linear decision boundary."}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<matplotlib.text.Text at 0x7f47325f7cc0>"},"execution_count":3,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::66a30858-075f-4d8c-a677-908909db88d1","text/plain":"<matplotlib.figure.Figure at 0x7f4780161438>"},"metadata":{},"output_type":"display_data"}],"source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\n# Split the data into training and testing sets and prepare the features and labels\ntrain, test = train_test_split(speeddf, test_size=0.2, random_state=23)\nfeatures_train = train[['Grade','Bumpiness']].values\nlabels_train = train['Speed'].values\nfeatures_test = test[['Grade','Bumpiness']].values\nlabels_test = test['Speed'].values\n\n# Load the model and fit the data\nsvcmodel = SVC(kernel='linear')\nsvcmodel.fit(features_train,labels_train)\n\n# Create our decision boundary mesh\n# point in the mesh\nx_min = 0.0; x_max = 1.0 # Mesh x size\ny_min = 0.0; y_max = 1.0  # Mesh y size\nh = .01  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max+h, h), np.arange(y_min, y_max+h, h))\n\n# Prepare the boundary \nZpred = pd.Series(svcmodel.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values\nZ = Zpred.reshape(xx.shape)\n\n# First plot our points\ntestfig1, ax = plt.subplots()\n\nplt.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1,axes=ax)\nax.set_aspect(1)\n\n# Plot test points\ngroups = test.groupby('Speed')\n# The next step is to cycle through the groups (based on our categories) and plot each one on the same axis.\nfor name, group in groups:\n    ax.plot(group['Grade'], group['Bumpiness'], marker='o', linestyle='', ms=8, label=name)\nax.legend(bbox_to_anchor=(1,0.5))\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')"}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"[[ 66  10]\n [  2 122]]\n"},{"data":{"image/png":"smc-blob::8675cdc7-2eb8-4c60-8834-1f9bcf6d79d9","text/plain":"<matplotlib.figure.Figure at 0x7f4732556c50>"},"metadata":{},"output_type":"display_data"}],"source":"# Let's look at the metrics for this fit:\nfrom sklearn.metrics import confusion_matrix\nclass_labels = [\"slow\", \"fast\"]\ny_pred = svcmodel.predict(features_test)\ncnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\nprint(cnf_matrix)\n\ndef show_confusion_matrix(cnf_matrix, class_labels, ax=None):\n    \n    if not ax:\n        plt.matshow(cnf_matrix,cmap=plt.cm.YlGn,alpha=0.7)\n        ax = plt.gca()\n    else:\n        ax.matshow(cnf_matrix,cmap=plt.cm.YlGn,alpha=0.7)\n    ax.set_xlabel('Predicted Label', fontsize=16)\n    ax.set_xticks(range(0,len(class_labels)))\n    ax.set_xticklabels(class_labels)\n    ax.set_ylabel('Actual Label', fontsize=16, rotation=90)\n    ax.set_yticks(range(0,len(class_labels)))\n    ax.set_yticklabels(class_labels)\n    ax.xaxis.set_label_position('top')\n    ax.xaxis.tick_top()\n\n    for row in range(len(cnf_matrix)):\n        for col in range(len(cnf_matrix[row])):\n            ax.text(col, row, cnf_matrix[row][col], va='center', ha='center', fontsize=16)\n        \nshow_confusion_matrix(cnf_matrix,class_labels)"}
{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Class-dependent Metrics\nSensitivity/Recall Score: [ 0.86842105  0.98387097]\nPrecision Score: [ 0.97058824  0.92424242]\nF1 Score: [ 0.91666667  0.953125  ]\n\nClass-independent Metrics\nAccuracy Score: 0.94\nMatthews Correlation Coefficient (MCC): 0.8733023707219416\n"}],"source":"import sklearn.metrics as metrics\n\nrecall_score = metrics.recall_score(labels_test, y_pred,labels=class_labels,average=None)\nprec_score = metrics.precision_score(labels_test, y_pred,labels=class_labels,average=None)\nf1_score = metrics.f1_score(labels_test, y_pred,labels=class_labels,average=None)\n\nacc_score = metrics.accuracy_score(labels_test, y_pred)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\n\nprint(\"Class-dependent Metrics\")\nprint(\"Sensitivity/Recall Score: {}\".format(recall_score))\n\nprint(\"Precision Score: {}\".format(prec_score))\nprint(\"F1 Score: {}\".format(f1_score))\n\nprint(\"\\nClass-independent Metrics\")\nprint(\"Accuracy Score: {}\".format(acc_score))\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n"}
{"cell_type":"markdown","metadata":{},"source":"At this point I want to go back to the last set of classifiers we looked at with this exact same dataset: the Perceptron and the Naïve Bayes. For comparison, here were the metrics for those two classifiers:\n\n#### Perceptron:\n***\nClass-dependent Metrics\n* Sensitivity/Recall Score: [ 1.          0.83870968]\n* Precision Score: [ 0.79166667  1.        ]\n* F1 Score: [ 0.88372093  0.9122807 ]\n\nClass-independent Metrics\n* Accuracy Score: 0.9\n* Matthews Correlation Coefficient (MCC): 0.8148487556741162\n\n##### Naïve Bayes:\n***\nClass-dependent Metrics\n* Sensitivity/Recall Score: [ 0.80263158  0.98387097]\n* Precision Score: [ 0.96825397  0.89051095]\n* F1 Score: [ 0.87769784  0.9348659 ]\n\nClass-independent Metrics\n* Accuracy Score: 0.915\n* Matthews Correlation Coefficient (MCC): 0.8218398836470786\n\n\nWe see that the SVC model did better than both of these other models in all of the metrics! Not bad considering it is a linear fit. Now we can look a little more closely and how the SVC model works. It picks a few data points from the training set to use as \"support\" points and then plots the decision boundary as a line between those points. So, in essence, it is a model that has the number of support points as the number of model parameters. That is important because it tells us about the model complexity. Let's look at our linear model and show which points the model is using as its support points."}
{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f47322af588>"},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::bba67727-6008-4b11-b664-420dcc062ed3","text/plain":"<matplotlib.figure.Figure at 0x7f473b036978>"},"metadata":{},"output_type":"display_data"}],"source":"support_points = features_train[svcmodel.support_]\n\n#We plot the decision boundary and the support points\nfigsvc1 ,ax = plt.subplots()\nax.set_title(\"N support points: {}\".format(len(support_points)))\nax.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\nax.set_aspect(1)\n\nax.set_xlabel('Grade')\nax.set_ylabel('Bumpiness')\nax.scatter(x=support_points[:,0],y=support_points[:,1],s=20, facecolors='none', edgecolors='r')"}
{"cell_type":"markdown","metadata":{},"source":"We see that there are actually a large number of support points in this model! So, even though it ends up being a linear decision boundary, it has quite a high complexity. Does the improvement in performance justify this increase in complexity? Perhaps...\n\nBefore we go on, we need to note that the SVC model only works well for small-ish datasets (less than 100,000 points). Beyond that, it will slow down considerably. It may be worth your time to try using this model on larger datasets, but I wanted to warn you about that.\n\n### First Hyperparameter: C\n\nLet's dive into the model hyperparameters! The only hyperparameter for the model at this point is the `C` parameter. The SVC model is always looking for a perfect boundary: it wants to perfectly classify every point in the training set. So, what do we do about points that just aren't going to be classified perfectly? We apply a \"penalty\" for those points and try and lower the penalty as much as we can to do as best as we can. The size of the penalty we apply is related to the `C` parameter. Let's try two extremes with our linear decision boundary to see what they do (it defaults to the value of `C=1.0` if we don't tell the model to use a different value). \n\nWe're going to use a set of sub-plots so we can put both the confusion matrix and the support vector points on the same line."}
{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.7768273338142284\n"},{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f4732316898>"},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::3b917f12-96c2-454e-a978-ae1927e2e477","text/plain":"<matplotlib.figure.Figure at 0x7f473d72ddd8>"},"metadata":{},"output_type":"display_data"}],"source":"# Start with a value of C=0.05\nsvcmodel2 = SVC(kernel='linear',C=.05)\nsvcmodel2.fit(features_train,labels_train)\nZ = pd.Series(svcmodel2.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\nsupport_points = features_train[svcmodel2.support_]\n\nfig = plt.figure()\nax1 = fig.add_subplot(121)\n\ny_pred = svcmodel2.predict(features_test)\ncnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\nshow_confusion_matrix(cnf_matrix,class_labels,ax=ax1)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n\nax2 = fig.add_subplot(122)\n# First plot our points\nax2.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\nax2.set_title(\"N support points: {}\".format(len(support_points)))\nax2.set_aspect(1)\nax2.set_xlabel('Grade')\nax2.set_ylabel('Bumpiness')\n# Circle the support points\n\nax2.scatter(x=support_points[:,0],y=support_points[:,1],s=20, facecolors='none', edgecolors='r')"}
{"cell_type":"markdown","metadata":{},"source":"Note that the number of support points has dramatically increased but the overall quality of the fit (as measured by the MCC) has decreased! We've added complexity and not improved our performance at all. This is called **overfitting** and we'll see more examples of it later.\n\nSo, let's go to the other extreme and make `C` large."}
{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.8725152490099218\n"},{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f47309c9b70>"},"execution_count":8,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::02dba7a6-f73b-460a-a99e-ec9bb533b63d","text/plain":"<matplotlib.figure.Figure at 0x7f474afafb38>"},"metadata":{},"output_type":"display_data"}],"source":"svcmodel3 = SVC(kernel='linear',C=1000)\nsvcmodel3.fit(features_train,labels_train)\n# Prepare the boundary \nZ = pd.Series(svcmodel3.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\nsupport_points = features_train[svcmodel3.support_]\n\nfig2 = plt.figure()\nax1 = fig2.add_subplot(121)\n\ny_pred = svcmodel3.predict(features_test)\ncnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\nshow_confusion_matrix(cnf_matrix,class_labels,ax=ax1)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n\nax2 = fig2.add_subplot(122)\n# First plot our points\nax2.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\nax2.set_aspect(1)\nax2.set_title(\"N support points: {}\".format(len(support_points)))\nax2.set_xlabel('Grade')\nax2.set_ylabel('Bumpiness')\n# Circle the support points\n\nax2.scatter(x=support_points[:,0],y=support_points[:,1],s=20, facecolors='none', edgecolors='r')"}
{"cell_type":"markdown","metadata":{},"source":"Now we've reduced the number of parameters without reducing the MCC very much at all. At this point it doesn't matter how much bigger we make `C`, the SVC algorithm can't do any better."}
{"cell_type":"markdown","metadata":{},"source":"### The RBF Kernel\n\nNow that we've looked at the linear SVC, we can extend this model in a very simple way: instead of demanding that the decision boundary be a straight line, we let the boundary wiggle between points. This gives us another hyperparameter to work with: $\\gamma$: this parameter tells the SVC how close it should try and get to any given point. The best thing to do is to try out a couple of combinations to see how they perform."}
{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.8733023707219416\n"},{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f47308932e8>"},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::9854d6fa-9142-40f5-bad5-265fefe67048","text/plain":"<matplotlib.figure.Figure at 0x7f47322f64e0>"},"metadata":{},"output_type":"display_data"}],"source":"svcmodel4 = SVC(kernel='rbf',C=1, gamma=1)\nsvcmodel4.fit(features_train,labels_train)\ny_pred = svcmodel4.predict(features_test)\n# Prepare the boundary \nZ = pd.Series(svcmodel4.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\nsupport_points = features_train[svcmodel4.support_]\n\nfig4 = plt.figure()\nax1 = fig4.add_subplot(121)\ncnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\nshow_confusion_matrix(cnf_matrix,class_labels,ax=ax1)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n\nax2 = fig4.add_subplot(122)\n# First plot our points\nax2.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\nax2.set_title(\"N support points: {}\".format(len(support_points)))\nax2.set_aspect(1)\nax2.set_xlabel('Grade')\nax2.set_ylabel('Bumpiness')\n# Circle the support points\n\nax2.scatter(x=support_points[:,0],y=support_points[:,1],s=20, facecolors='none', edgecolors='r')"}
{"cell_type":"markdown","metadata":{},"source":"This looks a lot like the linear boundary! We'll try changing the values to see what they do."}
{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.8526304166916007\n"},{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f47307d7160>"},"execution_count":10,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::6f261288-cc95-405c-a2d9-7389a91ffdd0","text/plain":"<matplotlib.figure.Figure at 0x7f47308e2898>"},"metadata":{},"output_type":"display_data"}],"source":"svcmodel5 = SVC(kernel='rbf',C=0.1, gamma=1)\nsvcmodel5.fit(features_train,labels_train)\ny_pred = svcmodel5.predict(features_test)\n# Prepare the boundary \nZ = pd.Series(svcmodel5.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\nsupport_points = features_train[svcmodel5.support_]\n\nfig5 = plt.figure()\nax1 = fig5.add_subplot(121)\ncnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\nshow_confusion_matrix(cnf_matrix,class_labels,ax=ax1)\nmatt_score = metrics.matthews_corrcoef(labels_test, y_pred)\nprint(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n\nax2 = fig5.add_subplot(122)\n# First plot our points\nax2.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\nax2.set_title(\"N support points: {}\".format(len(support_points)))\nax2.set_aspect(1)\nax2.set_xlabel('Grade')\nax2.set_ylabel('Bumpiness')\n# Circle the support points\n\nax2.scatter(x=support_points[:,0],y=support_points[:,1],s=20, facecolors='none', edgecolors='r')"}
{"cell_type":"markdown","metadata":{},"source":"Reducing the penalty looks like it added a bit of curvature, but it increased the number of support points and lowered the MCC. Let's try the other way.\n\n#### Programming Aside Note:\n\nTake a quick look at the previous two blocks of code: they were identical except for a couple of parameters at the top. This is a good indication that we should write our own function to simplify running more examples. Python makes that really easy: we add one line at the top, change the parameter inputs to the model, and indent the rest of the code."}
{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.8830473335328681\n"},{"data":{"image/png":"smc-blob::f05883bc-4bc3-47dd-a0b1-ba2cdc9f9524","text/plain":"<matplotlib.figure.Figure at 0x7f473be199b0>"},"metadata":{},"output_type":"display_data"}],"source":"def testsvcmodel(inputC,inputgamma):\n    svcmodelf = SVC(kernel='rbf',C=inputC, gamma=inputgamma)\n    svcmodelf.fit(features_train,labels_train)\n    y_pred = svcmodelf.predict(features_test)\n    # Prepare the boundary \n    Z = pd.Series(svcmodelf.predict(np.c_[xx.ravel(), yy.ravel()]), dtype='category').cat.codes.values.reshape(xx.shape)\n    support_points = features_train[svcmodelf.support_]\n\n    figf = plt.figure()\n    ax1 = figf.add_subplot(121)\n    cnf_matrix = confusion_matrix(labels_test, y_pred,labels=class_labels)\n    show_confusion_matrix(cnf_matrix,class_labels,ax=ax1)\n    matt_score = metrics.matthews_corrcoef(labels_test, y_pred)\n    print(\"Matthews Correlation Coefficient (MCC): {}\".format(matt_score))\n\n    ax2 = figf.add_subplot(122)\n    # First plot our points\n    ax2.pcolormesh(xx, yy, Z, cmap= plt.cm.cool, alpha=0.1)\n    ax2.set_title(\"N support points: {}\".format(len(support_points)))\n    ax2.set_aspect(1)\n    ax2.set_xlabel('Grade')\n    ax2.set_ylabel('Bumpiness')\n    # Circle the support points\n\n    ax2.scatter(x=support_points[:,0],y=support_points[:,1],s=10, facecolors='none', edgecolors='r')\n\n# Now we just need to call the function!\ntestsvcmodel(inputC=100,inputgamma=1)"}
{"cell_type":"markdown","metadata":{},"source":"So we've reduced the number of support points and *increased* the performance of the model! The boundary is no longer a straight line, but it seems to do better than the straight line did. This is an example of reducing complexity **and** improving performance. That's the direction we want to go! Let's try the other hyperparameter: $\\gamma$.\n"}
{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.9151103565365025\n"},{"data":{"image/png":"smc-blob::e19562a6-19d8-404e-8dc6-c501ab10023e","text/plain":"<matplotlib.figure.Figure at 0x7f473d730748>"},"metadata":{},"output_type":"display_data"}],"source":"testsvcmodel(inputC=100,inputgamma=50)"}
{"cell_type":"markdown","metadata":{},"source":"So we've improved performance again! But this time, look at the support points and the decision boundary: they are both a mess! This is a complicated model that is trying hard to fit a very particular shape that doesn't look like it is really our dataset. In other words, it looks like it is trying to fit to the noise in the data as opposed to fitting the underlying model. This is what we mean by **overfitting** and it is going the wrong way! This type of model will most likely perform poorly when we head out to try it in the \"real world\".\n\nWe'll try the other combinations now."}
{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.893548021473575\n"},{"data":{"image/png":"smc-blob::c258394e-c591-4ae7-afdc-6686c7c38184","text/plain":"<matplotlib.figure.Figure at 0x7f473066a630>"},"metadata":{},"output_type":"display_data"}],"source":"testsvcmodel(inputC=1,inputgamma=50)"}
{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.883047333532868\n"},{"data":{"image/png":"smc-blob::0fb56394-ab40-42a3-b43d-643447f3fd5a","text/plain":"<matplotlib.figure.Figure at 0x7f473083a4e0>"},"metadata":{},"output_type":"display_data"}],"source":"testsvcmodel(inputC=0.1,inputgamma=50)"}
{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.8620192068216507\n"},{"data":{"image/png":"smc-blob::03bedb83-75a2-4a91-9a04-002062e766e0","text/plain":"<matplotlib.figure.Figure at 0x7f47309944a8>"},"metadata":{},"output_type":"display_data"}],"source":"testsvcmodel(inputC=100,inputgamma=0.1)"}
{"cell_type":"code","execution_count":16,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Matthews Correlation Coefficient (MCC): 0.3893166361692745\n"},{"data":{"image/png":"smc-blob::9cb9ebd3-b01a-4869-b5a7-2b9a66ccdea0","text/plain":"<matplotlib.figure.Figure at 0x7f47309a7d30>"},"metadata":{},"output_type":"display_data"}],"source":"testsvcmodel(inputC=0.1,inputgamma=0.1)"}
{"cell_type":"markdown","metadata":{},"source":"So, looking at all of these together, it looks like our best performance with the simplest model was where we had `C=100` and $\\gamma$`=1`. If we want to try to do even better, we could tune the paramters even further by exploring around this point to see if we can do a little better. Later in the course we'll take a look at tools that will simplify doing that optimization for us.\n\n\n## Support Vector Regressions\n\nWe can use this same type of tool to make predictions for continuous data as well. We will return to the fake data we used in Class 02 to see how to apply the SVM regression."}
{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f4730469400>"},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::0c93b937-0fac-48bf-bc76-214eba3874ae","text/plain":"<matplotlib.figure.Figure at 0x7f473055c0f0>"},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"smc-blob::976aa78d-1b27-4ff4-bcf3-72dfc9d4185d","text/plain":"<matplotlib.figure.Figure at 0x7f473045fa90>"},"metadata":{},"output_type":"display_data"}],"source":"fakedata2 = pd.read_csv('../Class02/Class02_fakedata2.csv')\nfaketrain2, faketest2 = train_test_split(fakedata2, test_size=0.2, random_state=23)\nfaketrain2.plot.scatter(x='input',y='output')\nfaketest2.plot.scatter(x='input',y='output')"}
{"cell_type":"markdown","metadata":{},"source":"As a reminder, let's review the linear regression along with its graph."}
{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"RMS Error: 0.041\n"},{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f47303bddd8>]"},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::27e2659e-6fc6-43d4-a6f6-37fa1a8455ca","text/plain":"<matplotlib.figure.Figure at 0x7f4730445978>"},"metadata":{},"output_type":"display_data"}],"source":"from sklearn.linear_model import LinearRegression\nregr = LinearRegression()\nfeatures = faketrain2[['input']].values\nlabels = faketrain2['output'].values\nregr.fit(features,labels)\n\ntestinputs = faketest2[['input']].values\npredictions = regr.predict(testinputs)\nactuals = faketest2['output'].values\nprint(\"RMS Error: {0:.3f}\".format( np.sqrt(np.mean((predictions - actuals) ** 2))))\n\n# Prepare the model line\nX_plot =np.linspace(0, 1, 1000)\nY_pred = regr.predict(X_plot[:,None])\n\ntrainfig, ax = plt.subplots()\n\n# First plot our points\nax.scatter(x=testinputs, y=actuals)\n\nax.plot(X_plot,Y_pred,c='r')"}
{"cell_type":"markdown","metadata":{},"source":"Ok, we now try the support vector regression model."}
{"cell_type":"code","execution_count":19,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"RMS Error: 0.072\n"},{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f4730535a90>]"},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::de3391a3-af7b-4042-8520-fb901e7c986a","text/plain":"<matplotlib.figure.Figure at 0x7f4732237d30>"},"metadata":{},"output_type":"display_data"}],"source":"from sklearn.svm import SVR\nsvrmodel = SVR(C=1.0,gamma=1.0)\n\nsvrmodel.fit(features,labels)\n\nsvrpredictions = svrmodel.predict(testinputs)\n\nprint(\"RMS Error: {0:.3f}\".format( np.sqrt(np.mean((svrpredictions - actuals) ** 2))))\n\n# Prepare the model line\nY_pred = svrmodel.predict(X_plot[:,None])\n\ntrainfig, ax = plt.subplots()\n# First plot our points\nax.scatter(x=testinputs, y=actuals)\nax.plot(X_plot,Y_pred,c='r')"}
{"cell_type":"markdown","metadata":{},"source":"That performance was worse than the linear model (an RMS error of 0.0 means a perfect fit). Let's try adjusting the hyperparameters. We'll make a function to make it easy to repeat this."}
{"cell_type":"code","execution_count":20,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::1af19ae2-ce4c-45c9-ba28-62a0828cb0a9","text/plain":"<matplotlib.figure.Figure at 0x7f47303cee80>"},"metadata":{},"output_type":"display_data"}],"source":"def svrtest(inputC, inputgamma):\n    svrmodel = SVR(C=inputC,gamma=inputgamma)\n    svrmodel.fit(features,labels)\n    svrpredictions = svrmodel.predict(testinputs)\n    \n    # Prepare the model line\n    Y_pred = svrmodel.predict(X_plot[:,None])\n    trainfig, ax = plt.subplots()\n    ax.set_title(\"RMS Error: {0:.3f}\".format( np.sqrt(np.mean((svrpredictions - actuals) ** 2))))\n    # First plot our points\n    ax.scatter(x=testinputs, y=actuals)\n    ax.plot(X_plot,Y_pred,c='r')\nsvrtest(100,1)"}
{"cell_type":"code","execution_count":21,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::cc665548-73dd-4c1d-81c4-300922291001","text/plain":"<matplotlib.figure.Figure at 0x7f4730416780>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(0.1,1)"}
{"cell_type":"code","execution_count":22,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::61357b22-8515-4cdb-a3b5-5298cbcb0370","text/plain":"<matplotlib.figure.Figure at 0x7f4730472320>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(1,100)"}
{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::f0994a79-b870-4044-ae78-373005856c18","text/plain":"<matplotlib.figure.Figure at 0x7f47304fca58>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(0.1,100)"}
{"cell_type":"code","execution_count":24,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::bcba5e34-901e-4157-b47e-925d6f538a7e","text/plain":"<matplotlib.figure.Figure at 0x7f4730447898>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(100,100)"}
{"cell_type":"code","execution_count":25,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::241a7efc-98f9-4b62-893f-a89b5e6d22a0","text/plain":"<matplotlib.figure.Figure at 0x7f47306df780>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(1,0.1)"}
{"cell_type":"code","execution_count":26,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::806e6ce7-5cfd-4dac-9e1c-4c128fc632af","text/plain":"<matplotlib.figure.Figure at 0x7f47306b5e10>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(100,0.1)"}
{"cell_type":"code","execution_count":27,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"image/png":"smc-blob::659678c0-134b-4a96-a10f-06957c1889bb","text/plain":"<matplotlib.figure.Figure at 0x7f47305bca20>"},"metadata":{},"output_type":"display_data"}],"source":"svrtest(0.1,0.1)"}
{"cell_type":"markdown","metadata":{},"source":"It looks like the best we can do with the SVR is actually *worse* than the linear regression! This is another example where model complexity doesn't necessarily improve performance. Occam's razor says we should go with the simplest model and, in this case, it is the linear regression."}
{"cell_type":"markdown","metadata":{},"source":"## In-class Activity\n\nWe used a multi-feature dataset in Class 02 to try out the regression. Use the SVM regression on that dataset to see if you can do any better in predicting the output.\n\n## Assignment\n\nImplement either the SVM classifier or regression on your own data. You can do multi-class predictions with the classifier so it should be able to handle pretty much any dataset. Record the time it takes for the model to fit on your data and compare that to the Perceptron and Naive Bayes models we did last week."}